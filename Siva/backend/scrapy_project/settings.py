# settings.py

BOT_NAME = "scrapy_project"

SPIDER_MODULES = ["scrapy_project.spiders"]
NEWSPIDER_MODULE = "scrapy_project.spiders"

USER_AGENT = "scrapy_project Spider (+http://www.yourdomain.com)"

ROBOTSTXT_OBEY = False

CONCURRENT_REQUESTS = 32

DOWNLOAD_DELAY = 0.5
RANDOMIZE_DOWNLOAD_DELAY = True

COOKIES_ENABLED = False

TELNETCONSOLE_ENABLED = False

ITEM_PIPELINES = {
    "scrapy_project.pipelines.SaveToFilePipeline": 300,
}

AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 5
AUTOTHROTTLE_MAX_DELAY = 60
AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
AUTOTHROTTLE_DEBUG = False

HTTPCACHE_ENABLED = True
HTTPCACHE_EXPIRATION_SECS = 0
HTTPCACHE_DIR = "httpcache"
HTTPCACHE_IGNORE_HTTP_CODES = []
HTTPCACHE_STORAGE = "scrapy.extensions.httpcache.FilesystemCacheStorage"


DEPTH_STATS_VERBOSE = True

LOG_LEVEL = "INFO"
DUPEFILTER_CLASS = "scrapy.dupefilters.BaseDupeFilter"
# Close the spider after idle
CLOSESPIDER_TIMEOUT = 0
CLOSESPIDER_PAGECOUNT = 0

HTTPCACHE_ENABLED = False

REQUEST_FINGERPRINTER_IMPLEMENTATION = "2.7"
